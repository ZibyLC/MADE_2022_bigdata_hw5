{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### HW5: Toxic Comment Classification with Spark"
      ],
      "metadata": {
        "id": "kGfJQ9dDza4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyspark"
      ],
      "metadata": {
        "id": "5_yYUkGWzctB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SOWiN1BvsiIT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.pipeline import Pipeline\n",
        "from pyspark.ml.classification import FMClassifier\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MultilabelClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start spark local session"
      ],
      "metadata": {
        "id": "ZCya3B4d0Mi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master('local[32]')\\\n",
        "        .appName('HW5')\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "-I2ux5h1z2UR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data"
      ],
      "metadata": {
        "id": "Sn3CS2Uq0N1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YuZxE67gsiIb"
      },
      "outputs": [],
      "source": [
        "train = spark.read.csv('train.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)\n",
        "test = spark.read.csv('test.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)\n",
        "test_labels = spark.read.csv('test_labels.csv', sep=',', quote='\\\"', escape='\\\"', multiLine=True, header=True, inferSchema=True)\n",
        "test = test.join(test_labels, 'id')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "k-CAZaZQ0PGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "VGPBFmIXsiIb"
      },
      "outputs": [],
      "source": [
        "res = []\n",
        "\n",
        "for numFeatures in range(10, 200, 10):\n",
        "    scores = []\n",
        "    tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
        "    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"tf\", numFeatures=20)\n",
        "    idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
        "    preprocessing = [tokenizer, hashingTF, idf,]\n",
        "\n",
        "    pipeline = Pipeline(stages=[tokenizer, hashingTF, idf,])\n",
        "\n",
        "    targets = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate',]\n",
        "    for target in targets:\n",
        "\n",
        "        model = LogisticRegression(featuresCol=idf.getOutputCol(), labelCol=target, maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "        metrics = BinaryClassificationEvaluator(labelCol=model.getLabelCol(), rawPredictionCol=model.getRawPredictionCol())\n",
        "\n",
        "        pipeline = Pipeline(stages=preprocessing + [model,])\n",
        "        pipeline = pipeline.fit(train)\n",
        "        scores.append(metrics.evaluate(pipeline.transform(test)))\n",
        "\n",
        "    res.append((numFeatures, sum(scores) / len(targets)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)"
      ],
      "metadata": {
        "id": "H9wD5smU6Q6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvAG3g2KsiIc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U3Y402WsiIc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}